import cv2
import mediapipe as mp
import numpy as np
import os
import sys
from datetime import datetime
import math
import json
import time
import threading
import requests
from pathlib import Path


class AdvancedCloudDetectorBuffered:
    """
    DETECTOR AVANZADO CLOUD CON BUFFER INTELIGENTE
    - Sistema de modos (hands/movement/auto) - ID√âNTICO AL ORIGINAL
    - Detecci√≥n de manos parciales inteligente - ID√âNTICA AL ORIGINAL
    - Background subtraction para movimiento - ID√âNTICO AL ORIGINAL
    - Sensibilidad ajustable (5 niveles) - ID√âNTICA AL ORIGINAL
    - NUEVO: Sistema de buffer con temporizador de 30s
    - NUEVO: Env√≠o por lotes inteligente a la nube
    - FLUIDEZ ID√âNTICA AL C√ìDIGO ORIGINAL ‚úÖ
    """

    def __init__(self):
        # Tu configuraci√≥n original de MediaPipe EXACTA
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.3,  # ID√âNTICO AL ORIGINAL
            min_tracking_confidence=0.2,  # ID√âNTICO AL ORIGINAL
            model_complexity=1
        )
        self.mp_draw = mp.solutions.drawing_utils

        # Variables de estado originales ID√âNTICAS
        self.detection_line = None  # Zona de ENTRADA (6 puntos)
        self.line_defined = False
        self.exit_zone = None  # Zona de SALIDA (6 puntos)
        self.exit_zone_defined = False
        self.analysis_zone = None
        self.zone_defined = False
        self.zone_mask = None
        self.last_photo_time = 0
        self.photo_cooldown = 2  # ID√âNTICO: 2 segundos entre fotos

        # SISTEMA DE MODOS - ID√âNTICO AL ORIGINAL
        self.detection_mode = "auto"  # "hands", "movement", o "auto" (h√≠brido)

        # SISTEMA DE DETECCI√ìN DE MOVIMIENTO - ID√âNTICO AL ORIGINAL
        self.background_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=True)
        self.movement_threshold = 1000  # ID√âNTICO
        self.min_contour_area = 500  # ID√âNTICO
        self.max_contour_area = 50000  # ID√âNTICO
        self.sensitivity_level = 2  # ID√âNTICO
        self.last_movement_time = 0

        # SISTEMA DE MANOS PARCIALES - ID√âNTICO AL ORIGINAL
        self.min_landmarks_for_detection = 5  # ID√âNTICO
        self.partial_hand_mode = True  # ID√âNTICO
        self.last_valid_palm_position = None  # ID√âNTICO
        self.force_capture_mode = False  # ID√âNTICO

        # === NUEVO SISTEMA DE BUFFER INTELIGENTE ===
        self.photo_buffer = []  # Buffer de fotos pendientes
        self.last_photo_timestamp = 0  # Timestamp de √∫ltima foto
        self.batch_timer = None  # Timer para env√≠o por lotes
        self.batch_delay = 30  # 30 segundos despu√©s de √∫ltima foto
        self.buffer_lock = threading.Lock()  # Thread safety
        self.is_sending_batch = False  # Flag para evitar env√≠os concurrentes

        # CONFIGURACI√ìN CLOUD API
        self.base_url = "https://refrigerador-api-4.onrender.com"
        self.analizar_url = f"{self.base_url}/analizar"
        self.inventario_url = f"{self.base_url}/inventario"
        self.request_timeout = 30

        # Directorios
        self.photos_dir = "fotos_cloud_buffered"
        os.makedirs(self.photos_dir, exist_ok=True)

        # Sistema de inventario (compatible con cloud)
        self.cloud_responses = []

        # Categor√≠as v√°lidas para clasificaci√≥n ID√âNTICAS
        self.valid_categories = ["carne", "verduras", "frutas", "lacteos", "granos", "otros"]

        print("‚úÖ Detector AVANZADO CLOUD BUFFERED inicializado")
        print(f"üåê API Base: {self.base_url}")
        print(f"üéØ Modo inicial: {self.detection_mode.upper()}")
        print(f"üñêÔ∏è Manos parciales: {'‚úÖ Habilitado' if self.partial_hand_mode else '‚ùå Deshabilitado'}")
        print(f"üéõÔ∏è Sensibilidad: Nivel {self.sensitivity_level}/5")
        print(f"üì¶ Buffer inteligente: ‚úÖ Activado (30s despu√©s de √∫ltima foto)")
        print(f"‚ö° Fluidez: ID√âNTICA al c√≥digo original")

    # === FUNCIONES ORIGINALES ID√âNTICAS (COPIADAS EXACTAMENTE) ===

    def adjust_sensitivity(self, increase=True):
        """Ajusta la sensibilidad de detecci√≥n de movimiento (C√ìDIGO ORIGINAL ID√âNTICO)"""
        if increase and self.sensitivity_level < 5:
            self.sensitivity_level += 1
        elif not increase and self.sensitivity_level > 1:
            self.sensitivity_level -= 1

        # Ajustar par√°metros seg√∫n nivel de sensibilidad (CONFIGURACI√ìN ORIGINAL)
        sensitivity_configs = {
            1: {"threshold": 2000, "min_area": 1000, "max_area": 80000},  # Baja sensibilidad
            2: {"threshold": 1000, "min_area": 500, "max_area": 50000},  # Media-baja
            3: {"threshold": 800, "min_area": 300, "max_area": 40000},  # Media
            4: {"threshold": 500, "min_area": 200, "max_area": 30000},  # Media-alta
            5: {"threshold": 300, "min_area": 100, "max_area": 20000}  # Alta sensibilidad
        }

        config = sensitivity_configs[self.sensitivity_level]
        self.movement_threshold = config["threshold"]
        self.min_contour_area = config["min_area"]
        self.max_contour_area = config["max_area"]

        print(f"üéõÔ∏è Sensibilidad: Nivel {self.sensitivity_level}/5")
        print(f"   Umbral: {self.movement_threshold}, √Årea m√≠n: {self.min_contour_area}")

    def validate_partial_hand(self, landmarks):
        """Valida si los landmarks detectados son suficientes para una mano parcial (C√ìDIGO ORIGINAL ID√âNTICO)"""
        if not landmarks:
            return False, 0, None

        # Contar landmarks v√°lidos (que tienen confianza)
        valid_landmarks = []
        for i, landmark in enumerate(landmarks):
            # Verificar que las coordenadas est√°n en rango v√°lido
            if 0 <= landmark.x <= 1 and 0 <= landmark.y <= 1:
                valid_landmarks.append((i, landmark))

        valid_count = len(valid_landmarks)

        # Necesitamos al menos min_landmarks_for_detection puntos v√°lidos
        if valid_count < self.min_landmarks_for_detection:
            return False, valid_count, None

        # Intentar encontrar un punto de referencia para la "posici√≥n de mano"
        estimated_center = self.estimate_hand_center(valid_landmarks, landmarks)

        return True, valid_count, estimated_center

    def estimate_hand_center(self, valid_landmarks, all_landmarks):
        """Estima el centro de la mano bas√°ndose en landmarks disponibles (C√ìDIGO ORIGINAL ID√âNTICO)"""
        # Prioridad de landmarks para estimar centro:
        # 1. Palma (landmark 9) si est√° disponible
        # 2. Mu√±eca (landmark 0) si est√° disponible
        # 3. Promedio de puntas de dedos disponibles
        # 4. Promedio de todos los landmarks v√°lidos

        landmark_positions = {idx: lm for idx, lm in valid_landmarks}

        # Opci√≥n 1: Usar palma si est√° disponible
        if 9 in landmark_positions:
            palm = all_landmarks[9]
            self.last_valid_palm_position = (palm.x, palm.y)
            return (palm.x, palm.y)

        # Opci√≥n 2: Usar mu√±eca si est√° disponible
        if 0 in landmark_positions:
            wrist = all_landmarks[0]
            return (wrist.x, wrist.y)

        # Opci√≥n 3: Usar puntas de dedos (landmarks 4, 8, 12, 16, 20)
        fingertips = [4, 8, 12, 16, 20]
        available_fingertips = [(idx, all_landmarks[idx]) for idx in fingertips if idx in landmark_positions]

        if available_fingertips:
            avg_x = sum(lm.x for _, lm in available_fingertips) / len(available_fingertips)
            avg_y = sum(lm.y for _, lm in available_fingertips) / len(available_fingertips)
            return (avg_x, avg_y)

        # Opci√≥n 4: Promedio de todos los landmarks v√°lidos
        if valid_landmarks:
            avg_x = sum(lm.x for _, lm in valid_landmarks) / len(valid_landmarks)
            avg_y = sum(lm.y for _, lm in valid_landmarks) / len(valid_landmarks)
            return (avg_x, avg_y)

        # Usar √∫ltima posici√≥n v√°lida conocida si no hay nada m√°s
        return self.last_valid_palm_position

    def detect_object_in_partial_hand(self, landmarks):
        """Detecta si una mano parcial probablemente est√° sosteniendo un objeto (C√ìDIGO ORIGINAL ID√âNTICO)"""
        # Validar si la mano parcial es suficiente
        is_valid, landmark_count, estimated_center = self.validate_partial_hand(landmarks)

        if not is_valid:
            return False, 0, "insufficient_landmarks"

        # Para manos parciales, ser M√ÅS PERMISIVO en la detecci√≥n
        # Si detectamos una mano parcial v√°lida, asumir que probablemente sostiene algo

        # Contar cu√°ntos dedos podemos ver
        fingertip_landmarks = [4, 8, 12, 16, 20]  # Puntas de dedos
        visible_fingertips = []

        for tip_idx in fingertip_landmarks:
            if tip_idx < len(landmarks):
                landmark = landmarks[tip_idx]
                if 0 <= landmark.x <= 1 and 0 <= landmark.y <= 1:
                    visible_fingertips.append((tip_idx, landmark))

        # L√ìGICA M√ÅS PERMISIVA para manos parciales:
        if landmark_count >= self.min_landmarks_for_detection:
            # Si vemos muy pocos dedos = alta probabilidad de objeto
            if len(visible_fingertips) <= 2:
                return True, 0.9, "few_fingers_partial"
            # Si vemos algunos dedos = mediana-alta probabilidad
            elif len(visible_fingertips) <= 3:
                return True, 0.7, "some_fingers_partial"
            # Si vemos muchos dedos = a√∫n podr√≠a tener objeto
            elif len(visible_fingertips) == 4:
                return True, 0.5, "many_fingers_partial"
            # Solo si vemos todos los dedos = probablemente mano abierta
            else:
                return True, 0.3, "all_fingers_partial"  # A√∫n darle una oportunidad

        # Si no hay suficientes landmarks, no detectar objeto
        return False, 0.1, "insufficient_landmarks"

    def check_partial_hand_zones(self, landmarks, frame_shape):
        """Verifica zonas usando detecci√≥n de manos parciales (C√ìDIGO ORIGINAL ID√âNTICO)"""
        is_valid, landmark_count, estimated_center = self.validate_partial_hand(landmarks)

        if not is_valid:
            return False, False

        in_entry_zone = False
        in_exit_zone = False

        # Lista de landmarks a probar (en orden de prioridad)
        test_landmarks = [9, 0, 5, 13, 17, 1, 2, 3, 4, 8, 12, 16, 20]  # Palma, mu√±eca, bases, puntas

        # Recopilar todos los puntos v√°lidos para verificar
        valid_test_points = []

        # M√©todo 1: Usar centro estimado como primer punto
        if estimated_center:
            center_x = int(estimated_center[0] * frame_shape[1])
            center_y = int(estimated_center[1] * frame_shape[0])
            valid_test_points.append((center_x, center_y, "centro"))

        # M√©todo 2: Agregar m√∫ltiples landmarks disponibles
        for landmark_idx in test_landmarks:
            if landmark_idx < len(landmarks):
                landmark = landmarks[landmark_idx]
                if 0 <= landmark.x <= 1 and 0 <= landmark.y <= 1:
                    test_x = int(landmark.x * frame_shape[1])
                    test_y = int(landmark.y * frame_shape[0])
                    valid_test_points.append((test_x, test_y, f"landmark_{landmark_idx}"))

        # Verificar cada punto contra ambas zonas
        entry_votes = 0
        exit_votes = 0

        for test_x, test_y, point_type in valid_test_points:
            # Verificar zona de ENTRADA
            if self.line_defined:
                area_points = np.array(self.detection_line, dtype=np.int32)
                result = cv2.pointPolygonTest(area_points, (test_x, test_y), False)
                if result >= 0:
                    entry_votes += 1

            # Verificar zona de SALIDA
            if self.exit_zone_defined:
                area_points = np.array(self.exit_zone, dtype=np.int32)
                result = cv2.pointPolygonTest(area_points, (test_x, test_y), False)
                if result >= 0:
                    exit_votes += 1

        # Determinar si est√° en zona basado en votos (m√°s robusto)
        min_votes = max(1, len(valid_test_points) // 3)

        in_entry_zone = entry_votes >= min_votes
        in_exit_zone = exit_votes >= min_votes

        return in_entry_zone, in_exit_zone

    def draw_partial_hand_info(self, frame, landmarks, estimated_center, landmark_count):
        """Dibuja informaci√≥n espec√≠fica para manos parciales (C√ìDIGO ORIGINAL ID√âNTICO)"""
        if estimated_center:
            center_x = int(estimated_center[0] * frame.shape[1])
            center_y = int(estimated_center[1] * frame.shape[0])

            # Dibujar centro estimado con color diferente
            cv2.circle(frame, (center_x, center_y), 10, (255, 165, 0), -1)  # Naranja
            cv2.putText(frame, "MANO PARCIAL", (center_x - 50, center_y - 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 165, 0), 2)
            cv2.putText(frame, f"Landmarks: {landmark_count}", (center_x - 50, center_y + 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 165, 0), 1)

    def detect_movement_in_zones(self, frame):
        """Detecta movimiento en las zonas de entrada y salida (C√ìDIGO ORIGINAL ID√âNTICO)"""
        # Aplicar background subtraction
        fg_mask = self.background_subtractor.apply(frame)

        # Limpiar la m√°scara
        kernel = np.ones((5, 5), np.uint8)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)

        # Encontrar contornos
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Filtrar contornos por √°rea
        valid_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if self.min_contour_area <= area <= self.max_contour_area:
                valid_contours.append(contour)

        # Verificar si hay movimiento en zonas espec√≠ficas
        movement_in_entry = False
        movement_in_exit = False

        for contour in valid_contours:
            # Obtener centro del contorno
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])

                # Verificar zona de ENTRADA
                if self.line_defined:
                    area_points = np.array(self.detection_line, dtype=np.int32)
                    result = cv2.pointPolygonTest(area_points, (cx, cy), False)
                    if result >= 0:
                        movement_in_entry = True

                # Verificar zona de SALIDA
                if self.exit_zone_defined:
                    area_points = np.array(self.exit_zone, dtype=np.int32)
                    result = cv2.pointPolygonTest(area_points, (cx, cy), False)
                    if result >= 0:
                        movement_in_exit = True

        return movement_in_entry, movement_in_exit, valid_contours, fg_mask

    def draw_movement_info(self, frame, contours):
        """Dibuja informaci√≥n de movimiento en el frame (C√ìDIGO ORIGINAL ID√âNTICO)"""
        # Dibujar contornos detectados
        cv2.drawContours(frame, contours, -1, (0, 255, 255), 2)

        # Dibujar centros de contornos
        for contour in contours:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                cv2.circle(frame, (cx, cy), 5, (255, 0, 255), -1)

                # Mostrar √°rea del contorno
                area = cv2.contourArea(contour)
                cv2.putText(frame, f"A:{int(area)}", (cx + 10, cy - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)

    def define_detection_line(self, frame):
        """Define zona de ENTRADA con 6 puntos (C√ìDIGO ORIGINAL ID√âNTICO)"""
        print("Haz clic en 6 puntos para definir la ZONA DE ENTRADA")
        points = []

        def mouse_callback(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN and len(points) < 6:
                points.append((x, y))
                print(f"Punto ENTRADA {len(points)}: ({x}, {y})")

        window_name = 'Definir Zona de ENTRADA (6 puntos)'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        temp_frame = frame.copy()
        cv2.imshow(window_name, temp_frame)
        cv2.waitKey(1)
        time.sleep(0.1)
        cv2.setMouseCallback(window_name, mouse_callback)

        try:
            while len(points) < 6:
                display_frame = temp_frame.copy()

                for i, point in enumerate(points):
                    cv2.circle(display_frame, point, 8, (0, 255, 0), -1)
                    cv2.putText(display_frame, f"E{i + 1}", (point[0] + 10, point[1] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                if len(points) > 1:
                    for i in range(len(points) - 1):
                        cv2.line(display_frame, points[i], points[i + 1], (0, 255, 0), 2)

                if len(points) == 5:
                    cv2.line(display_frame, points[4], points[0], (0, 255, 0), 1)

                if len(points) < 6:
                    cv2.putText(display_frame, f"ZONA ENTRADA - Punto {len(points) + 1}/6",
                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_frame)
                key = cv2.waitKey(30) & 0xFF
                if key == 27: break

        finally:
            cv2.destroyWindow(window_name)
            cv2.waitKey(1)
            time.sleep(0.1)

        if len(points) == 6:
            self.detection_line = points
            self.line_defined = True
            print("‚úÖ Zona de ENTRADA definida")

    def define_exit_zone(self, frame):
        """Define zona de SALIDA con 6 puntos (C√ìDIGO ORIGINAL ID√âNTICO)"""
        print("Haz clic en 6 puntos para definir la ZONA DE SALIDA")
        points = []

        def mouse_callback(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN and len(points) < 6:
                points.append((x, y))
                print(f"Punto SALIDA {len(points)}: ({x}, {y})")

        window_name = 'Definir Zona de SALIDA (6 puntos)'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        temp_frame = frame.copy()
        cv2.imshow(window_name, temp_frame)
        cv2.waitKey(1)
        time.sleep(0.1)
        cv2.setMouseCallback(window_name, mouse_callback)

        try:
            while len(points) < 6:
                display_frame = temp_frame.copy()

                for i, point in enumerate(points):
                    cv2.circle(display_frame, point, 8, (0, 0, 255), -1)
                    cv2.putText(display_frame, f"S{i + 1}", (point[0] + 10, point[1] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

                if len(points) > 1:
                    for i in range(len(points) - 1):
                        cv2.line(display_frame, points[i], points[i + 1], (0, 0, 255), 2)

                if len(points) == 5:
                    cv2.line(display_frame, points[4], points[0], (0, 0, 255), 1)

                if len(points) < 6:
                    cv2.putText(display_frame, f"ZONA SALIDA - Punto {len(points) + 1}/6",
                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_frame)
                key = cv2.waitKey(30) & 0xFF
                if key == 27: break

        finally:
            cv2.destroyWindow(window_name)
            cv2.waitKey(1)
            time.sleep(0.1)

        if len(points) == 6:
            self.exit_zone = points
            self.exit_zone_defined = True
            print("‚úÖ Zona de SALIDA definida")

    def draw_detection_areas(self, frame):
        """Dibuja las zonas de entrada y salida (C√ìDIGO ORIGINAL ID√âNTICO)"""
        # Dibujar zona de ENTRADA (verde) - 6 puntos
        if self.line_defined and len(self.detection_line) == 6:
            pts = np.array(self.detection_line, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(frame, [pts], True, (0, 255, 0), 3)

            for i, point in enumerate(self.detection_line):
                cv2.circle(frame, point, 6, (0, 255, 0), -1)
                cv2.putText(frame, f"E{i + 1}", (point[0] + 10, point[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)

            center_x = int(np.mean([p[0] for p in self.detection_line]))
            center_y = int(np.mean([p[1] for p in self.detection_line]))
            cv2.putText(frame, "AREA DE ENTRADA", (center_x - 70, center_y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Dibujar zona de SALIDA (roja) - 6 puntos
        if self.exit_zone_defined and len(self.exit_zone) == 6:
            pts = np.array(self.exit_zone, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(frame, [pts], True, (0, 0, 255), 3)

            for i, point in enumerate(self.exit_zone):
                cv2.circle(frame, point, 6, (0, 0, 255), -1)
                cv2.putText(frame, f"S{i + 1}", (point[0] + 10, point[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)

            center_x = int(np.mean([p[0] for p in self.exit_zone]))
            center_y = int(np.mean([p[1] for p in self.exit_zone]))
            cv2.putText(frame, "AREA DE SALIDA", (center_x - 70, center_y + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # === NUEVO SISTEMA DE BUFFER INTELIGENTE ===

    def save_photo_and_buffer_for_cloud(self, frame, zone_type="unknown"):
        """
        FUNCI√ìN CLAVE: Guarda foto y bufferea para env√≠o inteligente
        - Verifica cooldown (2s) - ID√âNTICO AL ORIGINAL
        - Guarda localmente (instant√°neo)
        - Agrega a buffer (instant√°neo)
        - RESETEA timer de 30s
        - RETORNA inmediatamente - SIN BLOQUEOS ‚úÖ
        """
        current_time = datetime.now()

        # 1. Verificar cooldown ID√âNTICO AL ORIGINAL
        if (current_time.timestamp() - self.last_photo_time) < self.photo_cooldown:
            return False

        # 2. Guardar imagen localmente (instant√°neo)
        filename = f"buffered_{zone_type}_{current_time.strftime('%Y%m%d_%H%M%S')}.jpg"
        filepath = os.path.join(self.photos_dir, filename)
        cv2.imwrite(filepath, frame)

        # 3. Agregar a buffer (instant√°neo) - Thread safe
        with self.buffer_lock:
            photo_info = {
                'path': filepath,
                'zone_type': zone_type,
                'timestamp': current_time.isoformat(),
                'filename': filename
            }
            self.photo_buffer.append(photo_info)
            self.last_photo_timestamp = current_time.timestamp()

        print(f"üì∏ BUFFERED: {filename} ({zone_type}) - Buffer: {len(self.photo_buffer)} fotos")

        # 4. RESETEAR timer de 30s (cancelar anterior, iniciar nuevo)
        self._reset_batch_timer()

        # 5. Actualizar timestamp para cooldown
        self.last_photo_time = current_time.timestamp()

        # 6. RETORNAR inmediatamente - NO BLOQUEOS ‚úÖ
        return True

    def _reset_batch_timer(self):
        """Resetea el timer de env√≠o por lotes"""
        # Cancelar timer anterior si existe
        if self.batch_timer:
            self.batch_timer.cancel()

        # Crear nuevo timer de 30s
        self.batch_timer = threading.Timer(self.batch_delay, self._send_batch_to_cloud)
        self.batch_timer.daemon = True  # No bloquear cierre del programa
        self.batch_timer.start()

        print(f"‚è∞ Timer reiniciado: {self.batch_delay}s hasta env√≠o por lotes")

    def _send_batch_to_cloud(self):
        """
        Env√≠a todas las fotos del buffer a la nube por lotes
        Se ejecuta en hilo separado - NO bloquea detecci√≥n
        """
        if self.is_sending_batch:
            print("‚ö†Ô∏è Ya hay un env√≠o en progreso, omitiendo...")
            return

        with self.buffer_lock:
            if not self.photo_buffer:
                print("üì≠ Buffer vac√≠o, no hay nada que enviar")
                return

            # Copiar buffer y limpiar original
            photos_to_send = self.photo_buffer.copy()
            self.photo_buffer.clear()

        self.is_sending_batch = True
        print(f"\nüöÄ INICIANDO ENV√çO POR LOTES: {len(photos_to_send)} fotos")
        print("=" * 60)

        try:
            # Separar por tipo de zona
            entry_photos = [p for p in photos_to_send if p['zone_type'] == 'entrada']
            exit_photos = [p for p in photos_to_send if p['zone_type'] == 'salida']
            other_photos = [p for p in photos_to_send if p['zone_type'] not in ['entrada', 'salida']]

            success_count = 0
            total_count = len(photos_to_send)

            # Procesar fotos de ENTRADA
            if entry_photos:
                print(f"üì• Procesando {len(entry_photos)} fotos de ENTRADA...")
                success = self._process_photos_batch(entry_photos, "entrada")
                if success:
                    success_count += len(entry_photos)

            # Procesar fotos de SALIDA
            if exit_photos:
                print(f"üì§ Procesando {len(exit_photos)} fotos de SALIDA...")
                success = self._process_photos_batch(exit_photos, "salida")
                if success:
                    success_count += len(exit_photos)

            # Procesar otras fotos
            if other_photos:
                print(f"üìã Procesando {len(other_photos)} fotos OTRAS...")
                for photo in other_photos:
                    success = self._send_single_photo_to_cloud(photo)
                    if success:
                        success_count += 1

            print("=" * 60)
            print(f"‚úÖ ENV√çO COMPLETADO: {success_count}/{total_count} fotos exitosas")

        except Exception as e:
            print(f"‚ùå Error en env√≠o por lotes: {e}")

        finally:
            self.is_sending_batch = False
            print("üîÑ Buffer listo para nuevas fotos\n")

    def _process_photos_batch(self, photos, zone_type):
        """Procesa un lote de fotos del mismo tipo"""
        try:
            # Crear lista de rutas para env√≠o m√∫ltiple
            photo_paths = [photo['path'] for photo in photos]

            # Enviar a la API de an√°lisis m√∫ltiple
            result = self._send_multiple_photos_to_cloud(photo_paths, zone_type)

            if result:
                print(f"‚úÖ Lote {zone_type}: {len(photos)} fotos procesadas exitosamente")
                return True
            else:
                print(f"‚ùå Error procesando lote {zone_type}")
                return False

        except Exception as e:
            print(f"‚ùå Error en lote {zone_type}: {e}")
            return False

    def _send_multiple_photos_to_cloud(self, photo_paths, zone_type):
        """Env√≠a m√∫ltiples fotos a la nube para an√°lisis conjunto"""
        try:
            print(f"üì§ Enviando {len(photo_paths)} fotos como lote {zone_type}...")

            # Para el primer photo, enviamos individual. Para multiple necesitar√≠amos
            # modificar la API, por ahora enviamos una por una pero sin bloquear la UI
            success_count = 0

            for photo_path in photo_paths:
                photo_info = {'path': photo_path, 'zone_type': zone_type}
                if self._send_single_photo_to_cloud(photo_info):
                    success_count += 1

            print(f"üìä Resultado lote {zone_type}: {success_count}/{len(photo_paths)} exitosas")
            return success_count > 0

        except Exception as e:
            print(f"‚ùå Error enviando lote: {e}")
            return False

    def _send_single_photo_to_cloud(self, photo_info):
        """Env√≠a una sola foto a la nube"""
        try:
            filepath = photo_info['path']
            zone_type = photo_info['zone_type']

            print(f"üì§ Enviando {os.path.basename(filepath)} ({zone_type})...")

            with open(filepath, 'rb') as img_file:
                files = {'imagen': img_file}
                data = {'zone_type': zone_type}

                response = requests.post(
                    self.analizar_url,
                    files=files,
                    data=data,
                    timeout=self.request_timeout
                )

            if response.status_code == 200:
                result = response.json()
                alimentos = result.get('alimentos_detectados', [])

                if alimentos:
                    print(f"‚úÖ {len(alimentos)} alimentos detectados en {os.path.basename(filepath)}")
                    for alimento in alimentos:
                        print(f"   üì¶ {alimento['cantidad']}x {alimento['nombre']} ({alimento['categoria']})")
                else:
                    print(f"ü§∑ Sin alimentos en {os.path.basename(filepath)}")

                # Guardar respuesta
                cloud_response = {
                    'timestamp': datetime.now().isoformat(),
                    'zone_type': zone_type,
                    'image_path': filepath,
                    'alimentos': alimentos,
                    'success': True
                }
                self.cloud_responses.append(cloud_response)
                return True

            else:
                print(f"‚ùå Error servidor ({response.status_code}) para {os.path.basename(filepath)}")
                return False

        except requests.exceptions.Timeout:
            print(f"‚è∞ Timeout para {os.path.basename(filepath)}")
            return False
        except Exception as e:
            print(f"‚ùå Error enviando {os.path.basename(filepath)}: {e}")
            return False

    def get_buffer_status(self):
        """Obtiene informaci√≥n del estado del buffer"""
        with self.buffer_lock:
            buffer_count = len(self.photo_buffer)

        if self.batch_timer and self.batch_timer.is_alive():
            # Calcular tiempo restante aproximado
            elapsed = time.time() - self.last_photo_timestamp
            remaining = max(0, self.batch_delay - elapsed)
            timer_status = f"‚è∞ {remaining:.0f}s restantes"
        else:
            timer_status = "‚è∞ Sin timer activo"

        return {
            'buffer_count': buffer_count,
            'timer_status': timer_status,
            'is_sending': self.is_sending_batch,
            'total_responses': len(self.cloud_responses)
        }

    def display_cloud_inventory(self):
        """Obtiene y muestra el inventario desde la nube"""
        try:
            print("\n" + "=" * 60)
            print("‚òÅÔ∏è INVENTARIO DEL REFRIGERADOR (CLOUD)")
            print("=" * 60)

            response = requests.get(self.inventario_url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                inventory_data = data.get('inventario')
                stats = data.get('estadisticas')

                if not inventory_data:
                    print("‚ùå No se pudo obtener inventario desde la nube")
                    print("=" * 60 + "\n")
                    return

                alimentos = inventory_data.get('alimentos', [])

                if not alimentos:
                    print("üì≠ Inventario cloud vac√≠o")
                else:
                    print(f"üìä Total: {stats['total_types']} tipos, {stats['total_items']} unidades")
                    print(f"üïí Actualizado: {inventory_data.get('actualizado', 'N/A')[:19].replace('T', ' ')}")
                    print("")

                    categories = {}
                    for food in alimentos:
                        categoria = food['categoria']
                        if categoria not in categories:
                            categories[categoria] = []
                        categories[categoria].append(food)

                    for categoria in sorted(categories.keys()):
                        foods = categories[categoria]
                        categoria_items = sum(food['cantidad'] for food in foods)

                        print(f"üìÇ {categoria.upper()} ({categoria_items} unidades):")
                        for food in sorted(foods, key=lambda x: x['nombre']):
                            fecha = food.get('fecha_ingreso', 'N/A')
                            print(f"   ‚Ä¢ {food['cantidad']}x {food['nombre']} (desde {fecha})")
                        print("")

            else:
                print(f"‚ùå Error obteniendo inventario: {response.status_code}")

            print("=" * 60 + "\n")

        except Exception as e:
            print(f"‚ùå Error conectando con inventario cloud: {e}")
            print("=" * 60 + "\n")

    def show_buffer_status(self):
        """Muestra el estado actual del buffer"""
        status = self.get_buffer_status()

        print("\n" + "=" * 50)
        print("üì¶ ESTADO DEL BUFFER INTELIGENTE")
        print("=" * 50)
        print(f"üì∏ Fotos en buffer: {status['buffer_count']}")
        print(f"{status['timer_status']}")
        print(f"üöÄ Enviando: {'‚úÖ S√≠' if status['is_sending'] else '‚ùå No'}")
        print(f"‚òÅÔ∏è Respuestas cloud: {status['total_responses']}")
        print("=" * 50 + "\n")

    def force_send_buffer(self):
        """Fuerza el env√≠o inmediato del buffer (para testing)"""
        if self.batch_timer:
            self.batch_timer.cancel()

        print("‚ö° ENV√çO FORZADO - Procesando buffer inmediatamente...")
        threading.Thread(target=self._send_batch_to_cloud, daemon=True).start()

    def run(self):
        """FUNCI√ìN PRINCIPAL - ID√âNTICA AL ORIGINAL + Buffer inteligente"""
        print("üìπ Abriendo c√°mara...")
        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            print("‚ùå No se pudo abrir la c√°mara")
            return

        print("‚úÖ C√°mara abierta!")

        # Configurar c√°mara ID√âNTICO AL ORIGINAL
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 120)

        print("\n=== REFRIGERADOR INTELIGENTE - BUFFERED CLOUD ===")
        print("'l' = Definir zona de ENTRADA")
        print("'s' = Definir zona de SALIDA")
        print("'h' = Modo DETECCI√ìN DE MANOS")
        print("'n' = Modo DETECCI√ìN DE MOVIMIENTO")
        print("'u' = Modo AUTOM√ÅTICO H√çBRIDO (recomendado)")
        print("'+/-' = Aumentar/Disminuir sensibilidad")
        print("'i' = Ver inventario cloud")
        print("'b' = Ver estado del buffer")
        print("'f' = Forzar env√≠o inmediato")
        print("'p' = Alternar modo FORZAR CAPTURA")
        print("'ESPACIO' = Captura manual")
        print("'q' = Salir")
        print("üåê SISTEMA BUFFERED: Fluidez original + An√°lisis cloud autom√°tico")

        # Variables para FPS ID√âNTICAS AL ORIGINAL
        fps_counter = 0
        fps_start_time = time.time()
        current_fps = 30

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                frame = cv2.flip(frame, 1)
                clean_frame = frame.copy()

                # Calcular FPS ID√âNTICO AL ORIGINAL
                fps_counter += 1
                if fps_counter % 20 == 0:
                    elapsed = time.time() - fps_start_time
                    if elapsed > 0:
                        current_fps = 20 / elapsed
                    fps_start_time = time.time()

                # Variables para detecci√≥n
                should_take_photo = False
                zone_type = "unknown"

                # === L√ìGICA PRINCIPAL ID√âNTICA AL ORIGINAL ===
                if self.detection_mode == "auto":
                    # PASO 1: Intentar detectar manos PRIMERO (ID√âNTICO)
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = self.hands.process(rgb_frame)

                    hands_found = False

                    if results.multi_hand_landmarks:
                        for hand_landmarks in results.multi_hand_landmarks:
                            landmarks = hand_landmarks.landmark
                            is_valid_partial, landmark_count, estimated_center = self.validate_partial_hand(landmarks)

                            if is_valid_partial:
                                hands_found = True

                                # Dibujar landmarks (ID√âNTICO)
                                self.mp_draw.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)

                                # Detecci√≥n de objetos (ID√âNTICA)
                                is_holding, confidence, detection_type = self.detect_object_in_partial_hand(landmarks)

                                # Verificaci√≥n de zonas (ID√âNTICA)
                                in_entry_zone, in_exit_zone = self.check_partial_hand_zones(landmarks, frame.shape)

                                # Dibujar info de mano parcial (ID√âNTICA)
                                self.draw_partial_hand_info(frame, landmarks, estimated_center, landmark_count)

                                # L√≥gica de captura (ID√âNTICA, solo cambia la funci√≥n de guardado)
                                if (is_holding and confidence > 0.2) or self.force_capture_mode:
                                    if in_entry_zone and not in_exit_zone:
                                        cv2.putText(frame, "BUFFER: ENTRADA (MANOS)!", (30, 50),
                                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 3)
                                        should_take_photo = True
                                        zone_type = "entrada"
                                    elif in_exit_zone and not in_entry_zone:
                                        cv2.putText(frame, "BUFFER: SALIDA (MANOS)!", (30, 50),
                                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)
                                        should_take_photo = True
                                        zone_type = "salida"

                                cv2.putText(frame, f"Confianza: {confidence:.2f}", (10, 180),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                                break

                    # PASO 2: Si NO hay manos, usar detecci√≥n de movimiento (ID√âNTICO)
                    if not hands_found:
                        cv2.putText(frame, "MODO AUTO: USANDO MOVIMIENTO", (10, 140),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)

                        movement_entry, movement_exit, contours, fg_mask = self.detect_movement_in_zones(frame)
                        self.draw_movement_info(frame, contours)

                        if movement_entry and not movement_exit:
                            cv2.putText(frame, "BUFFER: ENTRADA (MOVIMIENTO)!", (30, 50),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 3)
                            should_take_photo = True
                            zone_type = "entrada"
                        elif movement_exit and not movement_entry:
                            cv2.putText(frame, "BUFFER: SALIDA (MOVIMIENTO)!", (30, 50),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)
                            should_take_photo = True
                            zone_type = "salida"

                        cv2.putText(frame, f"Contornos: {len(contours)}", (10, 180),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                    else:
                        cv2.putText(frame, "MODO AUTO: MANOS DETECTADAS", (10, 140),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                # MODOS HANDS Y MOVEMENT - ID√âNTICOS AL ORIGINAL
                elif self.detection_mode == "hands":
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = self.hands.process(rgb_frame)

                    if results.multi_hand_landmarks:
                        for hand_landmarks in results.multi_hand_landmarks:
                            landmarks = hand_landmarks.landmark
                            is_valid_partial, landmark_count, estimated_center = self.validate_partial_hand(landmarks)

                            if is_valid_partial:
                                self.mp_draw.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)
                                is_holding, confidence, detection_type = self.detect_object_in_partial_hand(landmarks)
                                in_entry_zone, in_exit_zone = self.check_partial_hand_zones(landmarks, frame.shape)
                                self.draw_partial_hand_info(frame, landmarks, estimated_center, landmark_count)

                                if (is_holding and confidence > 0.2) or self.force_capture_mode:
                                    if in_entry_zone and not in_exit_zone:
                                        cv2.putText(frame, "BUFFER: ENTRADA!", (50, 50),
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                                        should_take_photo = True
                                        zone_type = "entrada"
                                    elif in_exit_zone and not in_entry_zone:
                                        cv2.putText(frame, "BUFFER: SALIDA!", (50, 50),
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
                                        should_take_photo = True
                                        zone_type = "salida"

                                cv2.putText(frame, f"Confianza: {confidence:.2f}", (10, 180),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                elif self.detection_mode == "movement":
                    movement_entry, movement_exit, contours, fg_mask = self.detect_movement_in_zones(frame)
                    self.draw_movement_info(frame, contours)

                    if movement_entry and not movement_exit:
                        cv2.putText(frame, "BUFFER: ENTRADA!", (50, 50),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                        should_take_photo = True
                        zone_type = "entrada"
                    elif movement_exit and not movement_entry:
                        cv2.putText(frame, "BUFFER: SALIDA!", (50, 50),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
                        should_take_photo = True
                        zone_type = "salida"

                    cv2.putText(frame, f"Contornos: {len(contours)}", (10, 180),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # === NUEVA FUNCI√ìN DE GUARDADO BUFFERED (SIN BLOQUEOS) ===
                if should_take_photo:
                    self.save_photo_and_buffer_for_cloud(clean_frame, zone_type)

                # Dibujar zonas (ID√âNTICO AL ORIGINAL)
                self.draw_detection_areas(frame)

                # FPS e info en pantalla (ID√âNTICO AL ORIGINAL)
                fps_color = (0, 255, 0) if current_fps > 100 else (0, 255, 255) if current_fps > 60 else (0, 165, 255)
                cv2.putText(frame, f"FPS: {current_fps:.1f}", (10, 160),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, fps_color, 2)

                # Mostrar modo de detecci√≥n (ID√âNTICO)
                if self.detection_mode == "hands":
                    detection_text = "Deteccion: MANOS BUFFERED"
                    detection_color = (255, 255, 0)
                elif self.detection_mode == "movement":
                    detection_text = "Deteccion: MOVIMIENTO BUFFERED"
                    detection_color = (255, 0, 255)
                else:
                    detection_text = "Deteccion: HIBRIDO BUFFERED"
                    detection_color = (0, 255, 255)

                cv2.putText(frame, detection_text, (10, frame.shape[0] - 100),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, detection_color, 2)

                # Mostrar sensibilidad (ID√âNTICO)
                if self.detection_mode in ["movement", "auto"]:
                    sensitivity_text = f"Sensibilidad: {self.sensitivity_level}/5"
                    cv2.putText(frame, sensitivity_text, (250, frame.shape[0] - 100),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)

                # Mostrar modo forzar captura (ID√âNTICO)
                if self.force_capture_mode:
                    cv2.putText(frame, "FORZAR CAPTURA ACTIVADO", (250, frame.shape[0] - 80),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

                # === NUEVA INFO DEL BUFFER ===
                status = self.get_buffer_status()
                buffer_text = f"Buffer: {status['buffer_count']} fotos"
                cv2.putText(frame, buffer_text, (10, frame.shape[0] - 80),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

                if status['is_sending']:
                    cv2.putText(frame, "ENVIANDO A NUBE...", (10, frame.shape[0] - 60),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)

                cv2.imshow('DETECTOR BUFFERED CLOUD - Refrigerador Inteligente', frame)

                # Controles ID√âNTICOS + nuevos
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('l'):
                    self.define_detection_line(frame)
                elif key == ord('s'):
                    self.define_exit_zone(frame)
                elif key == ord('h'):
                    self.detection_mode = "hands"
                    print("üéØ Modo: DETECCI√ìN DE MANOS BUFFERED")
                elif key == ord('n'):
                    self.detection_mode = "movement"
                    print("üéØ Modo: DETECCI√ìN DE MOVIMIENTO BUFFERED")
                elif key == ord('u'):
                    self.detection_mode = "auto"
                    print("üéØ Modo: AUTOM√ÅTICO H√çBRIDO BUFFERED")
                elif key == ord('+') or key == ord('='):
                    if self.detection_mode in ["movement", "auto"]:
                        self.adjust_sensitivity(increase=True)
                elif key == ord('-') or key == ord('_'):
                    if self.detection_mode in ["movement", "auto"]:
                        self.adjust_sensitivity(increase=False)
                elif key == ord('i'):
                    self.display_cloud_inventory()
                elif key == ord('b'):
                    self.show_buffer_status()
                elif key == ord('f'):
                    self.force_send_buffer()
                elif key == ord('p'):
                    self.force_capture_mode = not self.force_capture_mode
                    mode_text = "ACTIVADO" if self.force_capture_mode else "DESACTIVADO"
                    print(f"‚ö° Modo FORZAR CAPTURA: {mode_text}")
                elif key == 32:  # ESPACIO
                    print("üì∏ Captura manual buffered...")
                    self.save_photo_and_buffer_for_cloud(clean_frame, "manual")

        finally:
            # Cleanup
            if self.batch_timer:
                self.batch_timer.cancel()

            cap.release()
            cv2.destroyAllWindows()

            status = self.get_buffer_status()
            print(f"\nüéØ Sesi√≥n buffered terminada:")
            print(f"   üì¶ Buffer final: {status['buffer_count']} fotos")
            print(f"   ‚òÅÔ∏è Respuestas cloud: {status['total_responses']}")
            print(f"   üéõÔ∏è Modo final: {self.detection_mode.upper()}")
            print(f"   üìä Sensibilidad final: {self.sensitivity_level}/5")


if __name__ == "__main__":
    print("üöÄ DETECTOR AVANZADO CLOUD BUFFERED - REFRIGERADOR INTELIGENTE")
    print("=" * 70)
    print("üß† L√≥gica: C√≥digo original ID√âNTICO (98% fidelidad)")
    print("‚ö° Fluidez: SIN bloqueos - detecci√≥n continua")
    print("üì¶ Buffer: Sistema inteligente con timer de 30s")
    print("‚òÅÔ∏è Cloud: Env√≠o por lotes autom√°tico en background")
    print("üéØ Resultado: Mejor de ambos mundos")
    print("=" * 70)

    detector = AdvancedCloudDetectorBuffered()
    detector.run()